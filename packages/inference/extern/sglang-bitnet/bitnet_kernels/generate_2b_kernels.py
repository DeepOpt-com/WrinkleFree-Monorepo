#!/usr/bin/env python3
"""Generate BitNet kernel headers for BitNet-b1.58-2B-4T model.

This script generates the kernel header and config files needed to convert
and run the BitNet-b1.58-2B-4T model with llama.cpp's BitNet kernels.

Usage:
    python generate_2b_kernels.py

This will generate:
    - bitnet_b1_58-2B-4T/kernel_config_tl1.ini (kernel dimensions)
    - bitnet_b1_58-2B-4T/bitnet-lut-kernels-tl1.h (kernel implementation)
"""

import os
import sys

# Add the BitNet utils directory to path for codegen imports
BITNET_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), '../../..', 'BitNet'))
sys.path.insert(0, os.path.join(BITNET_ROOT, 'utils'))

# Model dimensions for BitNet-b1.58-2B-4T
# hidden_size=2560, intermediate_size=6912, num_kv_heads=5, head_dim=128
MODEL_SHAPES_2B = [
    [2560, 6912],  # gate_proj, up_proj: hidden -> intermediate
    [2560, 2560],  # q_proj, o_proj: hidden -> hidden
    [6912, 2560],  # down_proj: intermediate -> hidden
    [640, 2560],   # k_proj, v_proj: hidden -> kv_dim (5 * 128 = 640)
]

# Kernel block parameters (tuned for x86_64 with AVX2)
# Format: [BM, BK, bm] for each shape
KERNEL_PARAMS_2B = [
    [160, 96, 32],   # 2560x6912
    [320, 128, 64],  # 2560x2560
    [288, 64, 32],   # 6912x2560
    [64, 128, 32],   # 640x2560
]


def generate_kernel_config():
    """Generate kernel_config_tl1.ini for the 2B model."""
    output_dir = os.path.join(os.path.dirname(__file__), 'bitnet_b1_58-2B-4T')
    os.makedirs(output_dir, exist_ok=True)

    config_path = os.path.join(output_dir, 'kernel_config_tl1.ini')

    comments = [
        "# gate_proj, up_proj: hidden -> intermediate",
        "# q_proj, o_proj: hidden -> hidden",
        "# down_proj: intermediate -> hidden",
        "# k_proj, v_proj: hidden -> kv_dim (GQA)",
    ]

    with open(config_path, 'w') as f:
        f.write("# Kernel configuration for BitNet-b1.58-2B-4T model\n")
        f.write("# Model: hidden_size=2560, intermediate_size=6912, kv_heads=5\n")
        f.write("# Generated for Fast-dLLM v2 / sglang-bitnet integration\n\n")

        for i, (shape, params) in enumerate(zip(MODEL_SHAPES_2B, KERNEL_PARAMS_2B)):
            f.write(f"[Kernels_{i}]\n")
            f.write(f"{comments[i]}\n")
            f.write(f"m = {shape[0]}\n")
            f.write(f"k = {shape[1]}\n")
            f.write(f"bm = {params[0]}\n")
            f.write(f"bk = {params[1]}\n")
            f.write(f"bmm = {params[2]}\n\n")

    print(f"Generated: {config_path}")
    return config_path


def generate_kernel_header():
    """Generate bitnet-lut-kernels-tl1.h using the codegen script."""
    try:
        from codegen_tl1 import (
            gen_tbl_impl, gen_top_api, gen_preprocess_code,
            gen_ctor_code, gen_transform_code
        )
    except ImportError:
        print("Warning: Could not import codegen_tl1 from BitNet.")
        print("Please ensure BitNet/utils is in your path.")
        print("Skipping header generation - use preset from BitNet if available.")
        return None

    output_dir = os.path.join(os.path.dirname(__file__), 'bitnet_b1_58-2B-4T')
    os.makedirs(output_dir, exist_ok=True)

    header_path = os.path.join(output_dir, 'bitnet-lut-kernels-tl1.h')

    # Generate kernel implementations
    tbl_impl_code = []
    for shape, params in zip(MODEL_SHAPES_2B, KERNEL_PARAMS_2B):
        BM, BK, bm = params
        tbl_impl_code.append(
            gen_tbl_impl(f"{shape[0]}_{shape[1]}", BM, BK, bm, shape[1])
        )

    api_code = gen_top_api(MODEL_SHAPES_2B)
    pre_code = gen_preprocess_code()
    ctor_code = gen_ctor_code()
    trans_code = gen_transform_code(MODEL_SHAPES_2B)

    with open(header_path, 'w') as f:
        f.write("// BitNet kernel implementation for BitNet-b1.58-2B-4T\n")
        f.write("// Generated by sglang-bitnet/bitnet_kernels/generate_2b_kernels.py\n\n")
        f.write("#if defined(GGML_BITNET_ARM_TL1)\n")
        f.write(ctor_code)
        for code in tbl_impl_code:
            f.write(code)
        f.write(pre_code)
        f.write(api_code)
        f.write(trans_code)
        f.write("#endif\n")

    print(f"Generated: {header_path}")
    return header_path


def main():
    print("Generating BitNet kernel files for BitNet-b1.58-2B-4T...")
    print(f"Model shapes: {MODEL_SHAPES_2B}")
    print(f"Kernel params: {KERNEL_PARAMS_2B}")
    print()

    # Generate config (always works)
    config_path = generate_kernel_config()

    # Generate header (requires codegen from BitNet)
    header_path = generate_kernel_header()

    print()
    print("Done! To use these kernels:")
    print("  1. Copy kernel_config_tl1.ini to include/kernel_config.ini")
    print("  2. Copy bitnet-lut-kernels-tl1.h to include/bitnet-lut-kernels.h")
    print("  3. Rebuild llama.cpp with BitNet support")


if __name__ == "__main__":
    main()
