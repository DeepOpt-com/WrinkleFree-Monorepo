# Default serving configuration

server:
  host: "0.0.0.0"
  port: 8080

inference:
  # Threading
  num_threads: 0  # 0 = auto-detect optimal threads

  # KV Cache
  context_size: 4096
  cache_type_k: f16
  cache_type_v: f16

  # Batching
  continuous_batching: true
  batch_size: 8

  # Memory
  mlock: true  # Lock model in memory

generation:
  # Sampling defaults
  temperature: 0.7
  top_p: 0.9
  top_k: 40
  max_tokens: 256

  # Stop sequences
  stop_sequences:
    - "\n\n"
    - "<|endoftext|>"

health:
  # Health check configuration
  initial_delay_seconds: 120  # Model loading time
  period_seconds: 10
  timeout_seconds: 5
