# Qwen3 4B - DLM Conversion Config
#
# Production-quality model for real-world use.
# Requires H100 GPU for efficient conversion.

name: qwen3_4b

# Source model (from WrinkleFree-1.58Quant)
source_pretrained: Qwen/Qwen3-4B-Base
bitnet_checkpoint: null  # Set via CLI

# Architecture
hidden_size: 2560
num_hidden_layers: 36
num_attention_heads: 32
num_kv_heads: 8
intermediate_size: 6912
vocab_size: 151936
max_position_embeddings: 40960

# Block diffusion parameters
block_size: 32
diffusion_steps: 8

# Conversion settings
conversion:
  preserve_quantization: true
  add_noise_embedding: true
  modify_attention_mask: true
