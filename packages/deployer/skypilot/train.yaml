# WrinkleFree Training Job
#
# Launch training as a managed job (auto-restart on preemption):
#   source credentials/.env
#   sky jobs launch train.yaml --secret WANDB_API_KEY --secret SKYPILOT_DOCKER_PASSWORD
#
# Or use the CLI (auto-prepares secrets):
#   wf train -m qwen3_4b -s 2 --cloud nebius
#
# Monitor:
#   sky jobs queue
#   sky jobs logs <job_id>
#
# Cancel:
#   sky jobs cancel <job_id>

name: wrinklefree-train

resources:
  # Docker image from Google Artifact Registry (GAR)
  image_id: docker:us-docker.pkg.dev/wrinklefree-481904/wf-train/wf-train:latest
  accelerators: H100:1  # Override from core.py based on scale
  use_spot: false  # On-demand for stability (spot keeps getting preempted)
  disk_size: 200  # GB - enough for checkpoints and model weights
  disk_tier: best
  cloud: nebius  # Nebius for H100 training
  job_recovery:
    max_restarts_on_errors: 3  # Handle NCCL timeouts, driver issues

# Sync local training code to cluster (monorepo paths)
workdir: ../training

# Mount dependencies and credentials
file_mounts:
  # CheaperTraining library for influence-based training
  ~/cheapertraining: ../cheapertraining
  # GCP credentials for GCS checkpointing
  ~/.config/gcloud/application_default_credentials.json: ~/.config/gcloud/application_default_credentials.json

envs:
  # Training configuration (override with -e)
  MODEL: qwen3_4b
  STAGE: "2"

  # Weights & Biases tracking
  WANDB_PROJECT: wrinklefree

  # Docker registry auth for pulling from GAR on non-GCP clouds
  SKYPILOT_DOCKER_USERNAME: _json_key
  SKYPILOT_DOCKER_SERVER: us-docker.pkg.dev

# Secrets are passed via --secret flag and redacted from logs/dashboard
secrets:
  WANDB_API_KEY: null           # Required - get from wandb.ai/authorize
  SKYPILOT_DOCKER_PASSWORD: null  # GCP service account JSON for Docker auth
  HF_TOKEN: null                # Optional - for gated HuggingFace models

setup: |
  set -e
  cd ~/sky_workdir

  # Base dependencies are pre-installed in the Docker image
  source /app/.venv/bin/activate

  # Install wrinklefree training package (editable)
  pip install -e . --no-deps

  # Install CheaperTraining for influence-based training
  pip install -e ~/cheapertraining --no-deps

  # Verify GPU setup
  python -c "import torch; print(f'GPUs: {torch.cuda.device_count()}'); [print(f'  {i}: {torch.cuda.get_device_name(i)}') for i in range(torch.cuda.device_count())]"

run: |
  set -e
  cd ~/sky_workdir
  source /app/.venv/bin/activate

  # Determine training config based on stage
  case $STAGE in
    1)   TRAINING_CONFIG="stage1_subln" ;;
    1.9) TRAINING_CONFIG="stage1_9_layerwise" ;;
    2)   TRAINING_CONFIG="stage2_pretrain" ;;
    3)   TRAINING_CONFIG="stage3_distill" ;;
    *)   echo "Unknown STAGE: $STAGE"; exit 1 ;;
  esac

  # Check for existing checkpoint to resume from
  CHECKPOINT_DIR="$HOME/checkpoints/${MODEL}/stage${STAGE}"
  mkdir -p $CHECKPOINT_DIR
  RESUME_FLAG=""
  if [ "$(ls -A $CHECKPOINT_DIR 2>/dev/null)" ]; then
    echo "Found existing checkpoint at $CHECKPOINT_DIR, resuming..."
    RESUME_FLAG="training.resume_from_checkpoint=$CHECKPOINT_DIR"
  else
    echo "No checkpoint found, starting fresh training..."
  fi

  # Determine data config based on stage
  case $STAGE in
    1)   DATA_CONFIG="" ;;  # Stage 1 doesn't need data
    1.9) DATA_CONFIG="data=fineweb" ;;
    2)   DATA_CONFIG="data=fineweb" ;;
    3)   DATA_CONFIG="data=downstream" ;;  # Fine-tuning uses task-specific data
    *)   DATA_CONFIG="data=fineweb" ;;
  esac

  # Debug: show configuration
  echo "HYDRA_OVERRIDES: ${HYDRA_OVERRIDES:-}"
  echo "RESUME_CHECKPOINT: ${RESUME_CHECKPOINT:-not set}"

  # Run training
  # Note: distributed config (single_gpu vs fsdp_multi) is set via HYDRA_OVERRIDES from core.py
  python scripts/train.py \
    model=${MODEL} \
    training=${TRAINING_CONFIG} \
    $DATA_CONFIG \
    output_dir=${CHECKPOINT_DIR} \
    $RESUME_FLAG \
    ${HYDRA_OVERRIDES:-}
