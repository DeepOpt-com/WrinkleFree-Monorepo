# Salient Columns Training - Qwen3-0.6B on Nebius 1x H100
#
# Full BitLinearSalient training run with AWQ-style activation-aware saliency:
# 1. Auto-converts model to BitNet
# 2. Calibrates salient columns using activation statistics
# 3. Converts BitLinear -> BitLinearSalient (~1% columns in FP16)
# 4. Trains 2.5B tokens with AdamW optimizer
# 5. Final 10% is SFT on Nemotron dataset
# 6. LDC-MTL auto-reweights objectives when curriculum phases change
#
# Based on:
# - AWQ: https://arxiv.org/abs/2306.00978
# - SqueezeLLM: https://arxiv.org/abs/2306.07629
# - SpQR: https://arxiv.org/abs/2306.03078
# - LDC-MTL: https://arxiv.org/abs/2502.08585
#
# Launch:
#   cd packages/deployer
#   source credentials/.env
#   sky launch skypilot/salient_qwen0.6b_1xh100.yaml -y --cluster wf-salient-0.6b
#
# Monitor:
#   sky logs wf-salient-0.6b
#
# Down:
#   sky down wf-salient-0.6b -y

name: wf-salient-qwen0.6b

resources:
  accelerators: H100:1
  memory: 64+
  disk_size: 200
  use_spot: false
  cloud: nebius

# Run from deployer directory
workdir: ../..

file_mounts:
  /tmp/gcp-creds.json: credentials/gcp-service-account.json
  /tmp/credentials.env: credentials/.env

envs:
  GOOGLE_APPLICATION_CREDENTIALS: /tmp/gcp-creds.json
  GOOGLE_CLOUD_PROJECT: wrinklefree-481904
  GCS_BUCKET: wrinklefree-checkpoints
  MODEL: qwen3_0.6b
  WANDB_PROJECT: wrinklefree
  HF_HUB_ENABLE_HF_TRANSFER: "1"
  TOTAL_TOKENS: "2_500_000_000"  # 2.5B tokens

setup: |
  set -e
  cd ~/sky_workdir

  if ! command -v uv &> /dev/null; then
    curl -LsSf https://astral.sh/uv/install.sh | sh
    export PATH="$HOME/.cargo/bin:$PATH"
  fi

  uv sync --all-packages

  # Verify imports
  printf "Verifying imports...\n"
  uv run python -c "from wf_arch import BitLinearSalient, convert_bitlinear_to_salient, calibrate_salient_columns; print('Salient imports OK')"

  printf "Setup complete\n"

run: |
  set -e
  cd ~/sky_workdir
  export PATH="$HOME/.cargo/bin:$PATH"

  set -a
  source /tmp/credentials.env
  set +a
  export HF_TOKEN="${HUGGINGFACE_WRITE_TOKEN}"

  echo "WANDB_API_KEY is set: $([ -n \"$WANDB_API_KEY\" ] && echo 'yes' || echo 'no')"

  CHECKPOINT_DIR="/tmp/checkpoints"
  mkdir -p $CHECKPOINT_DIR

  echo "=============================================="
  echo "BitLinearSalient Full Training Run"
  echo "=============================================="
  echo "Model: ${MODEL} (Qwen3-0.6B)"
  echo "Tokens: ${TOTAL_TOKENS}"
  echo ""
  echo "Training schedule:"
  echo "  0-25%:  Warmup on FineWeb (CE + DLM)"
  echo "  25-90%: Main training on mixed_pretrain (CE + DLM)"
  echo "  90-100%: SFT on Nemotron dataset"
  echo ""
  echo "Key features:"
  echo "  - ~1% of columns kept in FP16 (AWQ-style saliency)"
  echo "  - End-to-end trainable (both FP16 and ternary)"
  echo "  - Lambda warmup for gradual quantization transition"
  echo "  - AdamW optimizer"
  echo "  - LDC-MTL: Auto objective weight learning (reinits on phase changes)"
  echo "  - ODM: Auto dataset weight learning (after warmup)"
  echo "=============================================="

  uv run --package wf-train python packages/training/scripts/train_lightning.py \
    model=${MODEL} \
    training=salient_run \
    training.total_tokens=${TOTAL_TOKENS} \
    training.batch_size=4 \
    training.gradient_accumulation_steps=32 \
    training.max_seq_length=1024 \
    training.logging.log_interval=2 \
    training.auto_batch_size=false \
    training.torch_compile.enabled=false \
    training.salient.calibration_samples=128 \
    training.meta_optimization.enabled=true \
    training.meta_optimization.ldc_mtl.enabled=true \
    training.meta_optimization.odm.enabled=true \
    training.checkpoint.save_interval=500 \
    training.validation.val_check_interval=500 \
    output_dir=$CHECKPOINT_DIR \
    experiment_name=salient_qwen0.6b_2.5B_meta \
    distributed=single_gpu \
    gcs.enabled=true \
    gcs.bucket=${GCS_BUCKET} \
    training.logging.wandb.enabled=true \
    training.logging.wandb.project=${WANDB_PROJECT}

  echo ""
  echo "=============================================="
  echo "SALIENT TRAINING COMPLETE!"
  echo ""
  echo "Check W&B: https://wandb.ai/${WANDB_PROJECT}"
  echo "Check GCS: gs://${GCS_BUCKET}/"
  echo "=============================================="
