# WrinkleFree Qwen3-0.6B Full Run on Nebius H100
#
# Training with MuonClip + AdamW optimizer on H100.
# Uses curriculum: CE + DLM -> ramp to distillation
#
# Features:
# - Model: Qwen3-0.6B
# - GPU: Nebius H100 (80GB VRAM)
# - Training: full_run (CE + DLM + distillation with curriculum)
# - Optimizer: MuonClip (Muon + AdamW)
# - Logging: WandB + GCS checkpoints
#
# Launch:
#   cd packages/deployer
#   source credentials/.env
#   sky launch skypilot/qwen3_0.6b_full_run_h100.yaml -y --cluster qwen3-full
#
# Monitor:
#   sky logs qwen3-full
#   WandB: https://wandb.ai/wrinklefree
#
# Teardown:
#   sky down qwen3-full -y

name: wrinklefree-qwen3-0.6b-full-run

resources:
  accelerators: H100:1
  memory: 64+
  use_spot: false
  cloud: nebius
  disk_size: 100

# Sync from InfluenceClean monorepo
workdir: /home/lev/code/WrinkleFreeWORKTREE/InfluenceClean

# Upload credentials
file_mounts:
  /tmp/gcp-creds.json: /home/lev/code/WrinkleFree/WrinkleFree-Deployer/credentials/gcp-service-account.json
  /tmp/credentials.env: /home/lev/code/WrinkleFree/WrinkleFree-Deployer/credentials/.env
  /tmp/global.env: ~/.config/.env.global

envs:
  GOOGLE_APPLICATION_CREDENTIALS: /tmp/gcp-creds.json
  GOOGLE_CLOUD_PROJECT: wrinklefree-481904
  GCS_BUCKET: wrinklefree-checkpoints
  MODEL: qwen3_0.6b
  WANDB_PROJECT: wrinklefree_v2
  WANDB_RUN_NAME: qwen3-0.6b-full-run-h100
  HF_HUB_ENABLE_HF_TRANSFER: "1"

setup: |
  set -e
  cd ~/sky_workdir

  # Install uv if not present
  if ! command -v uv &> /dev/null; then
    curl -LsSf https://astral.sh/uv/install.sh | sh
    export PATH="$HOME/.cargo/bin:$PATH"
  fi

  # Install gcloud SDK for GCS uploads
  if ! command -v gcloud &> /dev/null; then
    echo "Installing Google Cloud SDK..."
    curl -sSL https://sdk.cloud.google.com | bash -s -- --disable-prompts --install-dir=$HOME
    export PATH="$HOME/google-cloud-sdk/bin:$PATH"
  fi

  # Configure gcloud with service account for GCS uploads
  if [ -f /tmp/gcp-creds.json ]; then
    echo "Activating GCP service account..."
    gcloud auth activate-service-account --key-file=/tmp/gcp-creds.json
    gcloud config set project wrinklefree-481904
    echo "GCS auth configured!"
  fi

  # Sync all packages
  uv sync --all-packages

  echo "Setup complete!"

run: |
  set -e
  cd ~/sky_workdir
  export PATH="$HOME/.cargo/bin:$HOME/google-cloud-sdk/bin:$PATH"

  # Load credentials
  source /tmp/credentials.env
  source /tmp/global.env
  export HF_TOKEN="${HUGGINGFACE_WRITE_TOKEN}"

  CHECKPOINT_DIR="/tmp/checkpoints"
  mkdir -p $CHECKPOINT_DIR

  echo "================================================================"
  echo "WrinkleFree Qwen3-0.6B Full Run (Nebius H100)"
  echo "================================================================"
  echo "Model: $MODEL (Qwen3-0.6B)"
  echo "GPU: Nebius H100 (80GB)"
  echo "Total tokens: 10B (full_run.yaml default)"
  echo ""
  echo "Configuration:"
  echo "  Training config: full_run"
  echo "  Curriculum phases:"
  echo "    - 0-10%: CE + DLM only (fineweb)"
  echo "    - 10-90%: CE + DLM (mixed_pretrain)"
  echo "    - 90-100%: CE + DLM + distillation"
  echo ""
  echo "  Objectives:"
  echo "    - continue_pretrain: Standard CE loss"
  echo "    - DLM: Mask prediction (mask_prob=0.15)"
  echo "    - distill: TCS-style sparse logits distillation"
  echo ""
  echo "  Optimizer: MuonClip (Muon + AdamW)"
  echo "    - lr_muon: 0.005"
  echo "    - lr_adam: 1e-4"
  echo "    - clipping_threshold: 10.0"
  echo ""
  echo "  Logging:"
  echo "    - WandB: ${WANDB_PROJECT}/${WANDB_RUN_NAME}"
  echo "    - GCS: gs://${GCS_BUCKET}/"
  echo "================================================================"

  # Run full_run training
  uv run --package wf-train python packages/training/scripts/train_lightning.py \
    model=${MODEL} \
    training=full_run \
    data.config_name=mixed_pretrain \
    distributed=single_gpu \
    output_dir=$CHECKPOINT_DIR \
    experiment_name=qwen3_0.6b_full_run \
    \
    training.auto_batch_size=true \
    training.auto_batch_size_margin=0.15 \
    \
    training.checkpoint.save_interval=500 \
    training.logging.log_interval=10 \
    training.logging.wandb.enabled=true \
    training.logging.wandb.project=${WANDB_PROJECT} \
    training.logging.wandb.name=${WANDB_RUN_NAME} \
    training.logging.wandb.tags="[qwen3-0.6b,full-run,h100,muonclip,ce-dlm-distill]" \
    gcs.enabled=true \
    gcs.bucket=${GCS_BUCKET}

  echo ""
  echo "================================================================"
  echo "Qwen3-0.6B Full Run Training Complete!"
  echo "================================================================"

  # Final checkpoint info
  echo ""
  echo "Final checkpoint:"
  ls -la $CHECKPOINT_DIR/qwen3_0.6b_full_run/checkpoints/ 2>/dev/null || echo "No local checkpoints"

  echo ""
  echo "GCS checkpoints:"
  gcloud storage ls "gs://${GCS_BUCKET}/experiments/" 2>/dev/null | grep qwen3 | head -10 || echo "GCS listing failed"

  echo ""
  echo "WandB run: https://wandb.ai/${WANDB_PROJECT}"
