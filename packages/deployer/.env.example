# WrinkleFree-Deployer Environment Configuration
#
# Copy this file to .env and fill in your credentials:
#   cp .env.example .env
#
# Then source it before running commands:
#   source .env
#   sky check
#
# IMPORTANT: Never commit .env to version control!

# ============================================================================
# AWS Credentials
# ============================================================================
# Get these from: AWS Console → IAM → Users → Security Credentials → Access Keys

AWS_ACCESS_KEY_ID=your-access-key-id
AWS_SECRET_ACCESS_KEY=your-secret-access-key
AWS_DEFAULT_REGION=us-east-1

# Optional: If using IAM roles or session tokens
# AWS_SESSION_TOKEN=your-session-token

# ============================================================================
# GCP Credentials
# ============================================================================
# Option 1: Service Account JSON (recommended for automation)
# Create at: GCP Console → IAM → Service Accounts → Create → Download JSON
GOOGLE_APPLICATION_CREDENTIALS=/path/to/your-service-account.json

# Option 2: Just set the project (if using gcloud auth)
# GCP_PROJECT_ID=your-project-id

# ============================================================================
# Azure Credentials (if using Azure)
# ============================================================================
# Get from: Azure Portal → Azure Active Directory → App Registrations
# AZURE_SUBSCRIPTION_ID=your-subscription-id
# AZURE_TENANT_ID=your-tenant-id
# AZURE_CLIENT_ID=your-client-id
# AZURE_CLIENT_SECRET=your-client-secret

# ============================================================================
# RunPod Credentials (for training jobs)
# ============================================================================
# Get from: https://www.runpod.io/console/user/settings → API Keys
RUNPOD_API_KEY=your-runpod-api-key

# ============================================================================
# Hetzner Credentials
# ============================================================================
# For Hetzner Cloud (VMs): https://console.hetzner.cloud/ → Security → API Tokens
HETZNER_API_TOKEN=your-hetzner-cloud-api-token

# For Hetzner Robot (Dedicated Servers): https://robot.hetzner.com/
# HETZNER_ROBOT_USER=your-robot-username
# HETZNER_ROBOT_PASSWORD=your-robot-password

# SSH key for Hetzner servers (path to private key)
HETZNER_SSH_KEY_PATH=~/.ssh/hetzner_ed25519

# ============================================================================
# Hetzner Server IPs (for SSH Node Pool)
# ============================================================================
# Comma-separated list of your Hetzner dedicated server IPs
# These will be registered with SkyPilot SSH Node Pools
HETZNER_SERVER_IPS=10.0.1.100,10.0.1.101,10.0.1.102

# ============================================================================
# OVHCloud Credentials (for Kubernetes integration)
# ============================================================================
# OVHCloud uses Kubernetes for SkyPilot integration
# Get these from: OVHcloud Control Panel → Public Cloud → Project

# Your OVHCloud Public Cloud project ID
OVHCLOUD_PROJECT_ID=your-project-id

# Path to your OVHCloud MKS kubeconfig file
# Download from: Public Cloud → Managed Kubernetes → Your Cluster → kubeconfig
OVHCLOUD_KUBECONFIG_PATH=~/.kube/ovhcloud-config

# Kubernetes context name (from kubeconfig)
OVHCLOUD_K8S_CONTEXT=kubernetes-admin@inference-cluster

# Optional: OVH API credentials (for CLI/automation)
# Get from: https://api.ovh.com/createToken/
# OVH_APPLICATION_KEY=your-application-key
# OVH_APPLICATION_SECRET=your-application-secret
# OVH_CONSUMER_KEY=your-consumer-key
# OVH_ENDPOINT=ovh-eu  # or ovh-us, ovh-ca

# ============================================================================
# Model Configuration
# ============================================================================
# Path to your model file
MODEL_PATH=./models/model.gguf

# Inference backend: bitnet or vllm
INFERENCE_BACKEND=bitnet

# ============================================================================
# Training Configuration
# ============================================================================
# Checkpoint storage backend: s3, gcs, r2, azure
CHECKPOINT_STORE=s3

# Checkpoint bucket name
# Create with: aws s3 mb s3://wrinklefree-checkpoints  (for S3)
#          or: gsutil mb gs://wrinklefree-checkpoints  (for GCS)
CHECKPOINT_BUCKET=wrinklefree-checkpoints

# Default training model
TRAINING_MODEL=qwen3_4b

# ============================================================================
# Service Configuration
# ============================================================================
# Name for your SkyServe service
SERVICE_NAME=wrinklefree-inference

# Minimum replicas (should match your Hetzner server count)
MIN_REPLICAS=3

# Maximum replicas (Hetzner + cloud burst capacity)
MAX_REPLICAS=20

# Target queries per second per replica
TARGET_QPS_PER_REPLICA=5.0

# ============================================================================
# WireGuard Configuration (Optional - for hybrid networking)
# ============================================================================
# WIREGUARD_PRIVATE_KEY=your-wireguard-private-key
# WIREGUARD_HUB_PUBLIC_KEY=hub-public-key
# WIREGUARD_HUB_ENDPOINT=your-hub-ip:51820

# ============================================================================
# Weights & Biases Configuration
# ============================================================================
# Get API key from: https://wandb.ai/authorize
WANDB_API_KEY=your-wandb-api-key

# Your W&B entity (username or team name)
# This was previously hardcoded to "umd-leans-well"
WANDB_ENTITY=umd-leans-well

# Default project name (matches constants.DEFAULT_WANDB_PROJECT)
WANDB_PROJECT=wrinklefree

# ============================================================================
# Modal Configuration
# ============================================================================
# Scale profile for Modal deployment: dev, small, medium, large, xlarge
# dev=1xA10G, small=1xH100, medium=2xH100, large=4xH100, xlarge=8xH100
MODAL_SCALE=dev

# Override GPU type if needed (usually determined by scale)
# MODAL_GPU_TYPE=H100

# Override GPU count if needed (usually determined by scale)
# MODAL_GPU_COUNT=1

# ============================================================================
# GitHub Token (for private repos)
# ============================================================================
# Optional: needed if WrinkleFree repos are private
# Get from: https://github.com/settings/tokens
# GH_TOKEN=your-github-token

# ============================================================================
# Monitoring (Optional)
# ============================================================================
# PROMETHEUS_ENDPOINT=http://prometheus:9090
# GRAFANA_API_KEY=your-grafana-api-key
