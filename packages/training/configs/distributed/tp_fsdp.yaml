# 2D Parallelism: Tensor Parallel + FSDP2
#
# Usage:
#   torchrun --nproc_per_node=8 scripts/train.py distributed=tp_fsdp
#
# TP shards model layers within nodes (uses NVLink)
# FSDP shards parameters across nodes (uses IB/ethernet)
#
# For 8 GPUs with tp_size=2: TP=2, DP=4
# For 8 GPUs with tp_size=4: TP=4, DP=2
# For 8 GPUs with tp_size=8: TP=8, DP=1 (pure TP)

backend: nccl
strategy: tp_fsdp

# Tensor Parallelism settings
tensor_parallel:
  enabled: true
  # TP degree: 0 = auto-infer (uses all GPUs on single node)
  # For multi-node: typically set to GPUs per node
  tp_size: 0

# FSDP2 settings (applied on DP dimension)
fsdp:
  enabled: true
  sharding_strategy: FULL_SHARD  # ZERO-3

  mixed_precision:
    enabled: true
    param_dtype: bfloat16
    reduce_dtype: float32  # Higher precision for gradient reduction
    buffer_dtype: bfloat16

  activation_checkpointing:
    enabled: true
    checkpoint_impl: NO_REENTRANT

  # Memory optimization
  backward_prefetch: BACKWARD_PRE
  forward_prefetch: false
  limit_all_gathers: true

  # State dict configuration
  state_dict:
    type: sharded
    offload_to_cpu: true

# Hardware configuration
num_gpus: 8
num_nodes: 1
